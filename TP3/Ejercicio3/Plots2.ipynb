{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5fc38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import parse_nums\n",
    "from src.perceptron import MultilayerPerceptron\n",
    "\n",
    "PATH = \"./data/Ej3B-digitos.txt\"\n",
    "\n",
    "OUTPUT_ACTIVATION = [\"TANH\", \"LOG\"]\n",
    "HIDDEN_ACTIVATION = [\"TANH\", \"LOG\"]\n",
    "BETA = 1\n",
    "\n",
    "TRAINING_TYPE = [\"PERCENTAGE\"]\n",
    "LR = 0.1\n",
    "BIAS = 1\n",
    "EPOCHS = 100000\n",
    "MIN_ERROR = 0.01\n",
    "TRAINING_PERCENTAGE = 0.9\n",
    "\n",
    "QTY_HIDDEN_LAYERS = 3\n",
    "QTY_NODES_IN_HIDDEN_LAYERS = [20, 16, 8]\n",
    "\n",
    "OPTIMIZER_METHOD = [\"MOMENTUM\", \"ADAM\"]\n",
    "K_FOLD = 4\n",
    "ALPHA = 0.8\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "input_data, expected_data = parse_nums(PATH, 7, 2)\n",
    "\n",
    "#-------------------------------------------------\n",
    "# VARIANDO EL LEARNING RATE\n",
    "#-------------------------------------------------\n",
    "\n",
    "arr_of_errors = []\n",
    "arr_of_epochs = []\n",
    "lrs = [round(LR*(10**(-i)),4) for i in range(4)]\n",
    "\n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    arr_of_error_aux = []\n",
    "    arr_of_epochs_aux = []\n",
    "    for out_act in OUTPUT_ACTIVATION:\n",
    "        arr_of_error_aux2 = []\n",
    "        arr_of_epochs_aux2 = []\n",
    "        for hidden_act in HIDDEN_ACTIVATION:\n",
    "            arr_of_error_aux3 = []\n",
    "            arr_of_epochs_aux3 = []\n",
    "            for lr in lrs:\n",
    "                perceptron = MultilayerPerceptron(input_data, expected_data, lr, BIAS,\n",
    "                                                EPOCHS, TRAINING_PERCENTAGE, MIN_ERROR,\n",
    "                                                QTY_HIDDEN_LAYERS, QTY_NODES_IN_HIDDEN_LAYERS, \n",
    "                                                out_act, hidden_act, BETA,\n",
    "                                                opt_method, ALPHA, BETA1, BETA2, EPSILON)\n",
    "                mse_errors, total_epochs, acurracy = perceptron.train()\n",
    "                arr_of_error_aux3.append(mse_errors)\n",
    "                arr_of_epochs_aux3.append(total_epochs)\n",
    "\n",
    "            arr_of_error_aux2.append(arr_of_error_aux3)\n",
    "            arr_of_epochs_aux2.append(arr_of_epochs_aux3)\n",
    "\n",
    "        arr_of_error_aux.append(arr_of_error_aux2)\n",
    "        arr_of_epochs_aux.append(arr_of_epochs_aux2)\n",
    "\n",
    "    arr_of_errors.append(arr_of_error_aux)\n",
    "    arr_of_epochs.append(arr_of_epochs_aux)\n",
    "    \n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    for j, out_act in enumerate(OUTPUT_ACTIVATION):\n",
    "        for k, hidden_act in enumerate(HIDDEN_ACTIVATION):\n",
    "            for s in range(len(arr_of_errors[i][j][k])):\n",
    "                plt.plot(range(arr_of_epochs[i][j][k][s]), arr_of_errors[i][j][k][s], color=colors[s], label=f\"Î·={lrs[s]}\")\n",
    "            plt.title(f'Perceptron Multicapa con optimizacion {opt_method} \\n output={out_act}, hidden={hidden_act}')\n",
    "            plt.xlabel(\"Epocas\")\n",
    "            plt.ylabel(\"Error (MSE)\")\n",
    "            plt.legend(loc='best', bbox_to_anchor=(1.2, 1.0))\n",
    "            plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# VARIANDO EL PORCENTAJE DE ENTRENAMIENTO\n",
    "#-------------------------------------------------\n",
    "\n",
    "OUTPUT_ACTIVATION = \"TANH\"\n",
    "HIDDEN_ACTIVATION = \"TANH\"\n",
    "BETA = 1.0\n",
    "\n",
    "TRAINING_TYPE = [\"PERCENTAGE\"]\n",
    "LR = 0.01\n",
    "BIAS = 1\n",
    "EPOCHS = 100000\n",
    "MIN_ERROR = 0.01\n",
    "\n",
    "QTY_HIDDEN_LAYERS = 3\n",
    "QTY_NODES_IN_HIDDEN_LAYERS = [20, 16, 8]\n",
    "\n",
    "OPTIMIZER_METHOD = [\"MOMENTUM\", \"ADAM\"]\n",
    "K_FOLD = 4\n",
    "ALPHA = 0.8\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "TRAIN_PERCENTAGES = [round(0.1*i,2) for i in range(4,11)]\n",
    "ITERATIONS = 20\n",
    "\n",
    "arr_avg_train_mses = []\n",
    "arr_std_train_mses = []\n",
    "arr_avg_test_mses = []\n",
    "arr_std_test_mses = []\n",
    "\n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    avg_train_mses = []\n",
    "    std_train_mses = []\n",
    "    avg_test_mses = []\n",
    "    std_test_mses = []\n",
    "    for p in TRAIN_PERCENTAGES:\n",
    "        train = []\n",
    "        test = []\n",
    "        for iter in range(ITERATIONS):\n",
    "            perceptron = MultilayerPerceptron(input_data, expected_data, LR, BIAS,\n",
    "                                                EPOCHS, p, MIN_ERROR,\n",
    "                                                QTY_HIDDEN_LAYERS, QTY_NODES_IN_HIDDEN_LAYERS, \n",
    "                                                OUTPUT_ACTIVATION, HIDDEN_ACTIVATION, BETA,\n",
    "                                                opt_method, ALPHA, BETA1, BETA2, EPSILON)\n",
    "            mse_errors, total_epochs, acurracy, test_mse = perceptron.train()\n",
    "            train.append(perceptron.train_MSE)\n",
    "            test.append(test_mse)\n",
    "            \n",
    "        train_aux = sum(train) / len(train)\n",
    "        avg_train_mses.append(train_aux)\n",
    "        error_train = np.std(train) / np.sqrt((len(train)))\n",
    "        std_train_mses.append(error_train)\n",
    "        \n",
    "        test_aux = sum(test) / len(test)\n",
    "        avg_test_mses.append(test_aux)\n",
    "        error_test = np.std(test) / np.sqrt((len(test)))\n",
    "        std_test_mses.append(error_test)\n",
    "                    \n",
    "    arr_avg_train_mses.append(avg_train_mses)\n",
    "    arr_std_train_mses.append(std_train_mses)\n",
    "    arr_avg_test_mses.append(avg_test_mses)\n",
    "    arr_std_test_mses.append(std_test_mses)\n",
    "    \n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    plt.errorbar(TRAIN_PERCENTAGES, arr_avg_train_mses[i], yerr=arr_std_train_mses[i], color=\"blue\", capsize=4, label=\"Train\")\n",
    "    plt.errorbar(TRAIN_PERCENTAGES, arr_avg_test_mses[i], yerr=arr_std_test_mses[i], color=\"red\", capsize=4, label=\"Test\")\n",
    "    plt.title(f'Perceptron Multicapa con optimizacion {opt_method} \\n output={OUTPUT_ACTIVATION}, hidden={HIDDEN_ACTIVATION}')\n",
    "    plt.xlabel(\"Porcentaje de entrenamiento\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend(loc='best', bbox_to_anchor=(1.2, 1.0))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

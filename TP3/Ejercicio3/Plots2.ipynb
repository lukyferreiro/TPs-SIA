{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc5fc38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Finished Training. \n",
      " MSE: 0.0009651833164739233\n",
      "Aca\n",
      "-0.5812114145510816\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 2.5002295375066326\n",
      "0\n",
      "Finished Training. \n",
      " MSE: 0.009433644309179257\n",
      "Aca\n",
      "0.913230945671125\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 3.660452651473627\n",
      "0\n",
      "Finished Training. \n",
      " MSE: 0.009942603537100803\n",
      "Aca\n",
      "-0.09933455770252875\n",
      "Test Acurracy: 1.0\n",
      "Test MSE = 0.8111982389488995\n",
      "0\n",
      "1000\n",
      "2000\n",
      "Finished Training. \n",
      " MSE: 0.009995618492881279\n",
      "Aca\n",
      "-0.5567941055341911\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 2.4236078870260025\n",
      "0\n",
      "Finished Training. \n",
      " MSE: 0.0014715866392177182\n",
      "Aca\n",
      "-0.9929821695802092\n",
      "Test Acurracy: 1.0\n",
      "Test MSE = 4.924994380094056e-05\n",
      "0\n",
      "Finished Training. \n",
      " MSE: 0.009773262688227466\n",
      "Aca\n",
      "-0.8593527453455359\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 3.457192631623981\n",
      "0\n",
      "1000\n",
      "Finished Training. \n",
      " MSE: 0.00998191750484046\n",
      "Aca\n",
      "0.6158498384091025\n",
      "Test Acurracy: 1.0\n",
      "Test MSE = 0.14757134665031268\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.009997953957878218\n",
      "Aca\n",
      "-0.6350212757254897\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 2.6732945720750076\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.5541698929191258\n",
      "Aca\n",
      "-0.9714783826942756\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 3.886727013430837\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.5506834330490764\n",
      "Aca\n",
      "-0.9916661048803834\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 3.9667338733293986\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.4302882903674219\n",
      "Aca\n",
      "-0.8392509051114985\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 0.7043420817304694\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.4764533806041894\n",
      "Aca\n",
      "-0.6676364367934178\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 2.7810112853210467\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.44196412668687474\n",
      "Aca\n",
      "0.330757575070745\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 0.10940057346667952\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Finished Training. \n",
      " MSE: 0.43716618711209293\n",
      "Aca\n",
      "0.9952674352564497\n",
      "Test Acurracy: 0.0\n",
      "Test MSE = 0.9905572676819513\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import parse_nums\n",
    "from src.perceptron import MultilayerPerceptron\n",
    "\n",
    "PATH = \"./data/Ej3B-digitos.txt\"\n",
    "\n",
    "OUTPUT_ACTIVATION = [\"TANH\", \"LOG\"]\n",
    "HIDDEN_ACTIVATION = [\"TANH\", \"LOG\"]\n",
    "BETA = 1\n",
    "\n",
    "TRAINING_TYPE = \"PERCENTAGE\"\n",
    "K_FOLD = 4\n",
    "LR = 0.1\n",
    "BIAS = 1\n",
    "EPOCHS = 10000\n",
    "MIN_ERROR = 0.01\n",
    "TRAINING_PERCENTAGE = 0.9\n",
    "\n",
    "QTY_HIDDEN_LAYERS = 2\n",
    "QTY_NODES_IN_HIDDEN_LAYERS = [16, 10]\n",
    "\n",
    "OPTIMIZER_METHOD = [\"MOMENTUM\", \"ADAM\"]\n",
    "K_FOLD = 4\n",
    "ALPHA = 0.8\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "input_data, expected_data = parse_nums(PATH, 7, 2)\n",
    "\n",
    "#-------------------------------------------------\n",
    "# VARIANDO EL LEARNING RATE\n",
    "#-------------------------------------------------\n",
    "\n",
    "arr_of_errors = []\n",
    "arr_of_epochs = []\n",
    "lrs = [round(LR*(10**(-i)),4) for i in range(4)]\n",
    "\n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    arr_of_error_aux = []\n",
    "    arr_of_epochs_aux = []\n",
    "    for out_act in OUTPUT_ACTIVATION:\n",
    "        arr_of_error_aux2 = []\n",
    "        arr_of_epochs_aux2 = []\n",
    "        for hidden_act in HIDDEN_ACTIVATION:\n",
    "            arr_of_error_aux3 = []\n",
    "            arr_of_epochs_aux3 = []\n",
    "            for lr in lrs:\n",
    "                perceptron = MultilayerPerceptron(input_data, expected_data, lr, BIAS,\n",
    "                                                EPOCHS, TRAINING_TYPE, TRAINING_PERCENTAGE, K_FOLD, MIN_ERROR,\n",
    "                                                QTY_HIDDEN_LAYERS, QTY_NODES_IN_HIDDEN_LAYERS, \n",
    "                                                out_act, hidden_act, BETA,\n",
    "                                                opt_method, ALPHA, BETA1, BETA2, EPSILON, [-1,1])\n",
    "                mse_errors, total_epochs, acurracy, test_mse = perceptron.train()\n",
    "                arr_of_error_aux3.append(mse_errors)\n",
    "                arr_of_epochs_aux3.append(total_epochs)\n",
    "\n",
    "            arr_of_error_aux2.append(arr_of_error_aux3)\n",
    "            arr_of_epochs_aux2.append(arr_of_epochs_aux3)\n",
    "\n",
    "        arr_of_error_aux.append(arr_of_error_aux2)\n",
    "        arr_of_epochs_aux.append(arr_of_epochs_aux2)\n",
    "\n",
    "    arr_of_errors.append(arr_of_error_aux)\n",
    "    arr_of_epochs.append(arr_of_epochs_aux)\n",
    "    \n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    for j, out_act in enumerate(OUTPUT_ACTIVATION):\n",
    "        for k, hidden_act in enumerate(HIDDEN_ACTIVATION):\n",
    "            for s in range(len(arr_of_errors[i][j][k])):\n",
    "                plt.plot(range(arr_of_epochs[i][j][k][s]), arr_of_errors[i][j][k][s], color=colors[s], label=f\"η={lrs[s]}\")\n",
    "            plt.title(f'Perceptron Multicapa con optimizacion {opt_method} \\n output={out_act}, hidden={hidden_act}')\n",
    "            plt.xlabel(\"Epocas\")\n",
    "            plt.ylabel(\"Error (MSE)\")\n",
    "            plt.legend(loc='best', bbox_to_anchor=(1.2, 1.0))\n",
    "            plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c3dc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 54\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ITERATIONS):\n\u001b[0;32m     49\u001b[0m     perceptron \u001b[39m=\u001b[39m MultilayerPerceptron(input_data, expected_data, LR, BIAS,\n\u001b[0;32m     50\u001b[0m                                         EPOCHS, TRAINING_TYPE, p, K_FOLD, MIN_ERROR,\n\u001b[0;32m     51\u001b[0m                                         QTY_HIDDEN_LAYERS, QTY_NODES_IN_HIDDEN_LAYERS, \n\u001b[0;32m     52\u001b[0m                                         OUTPUT_ACTIVATION, HIDDEN_ACTIVATION, BETA,\n\u001b[0;32m     53\u001b[0m                                         opt_method, ALPHA, BETA1, BETA2, EPSILON,  [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 54\u001b[0m     mse_errors, total_epochs, test_acurracy, test_mse \u001b[39m=\u001b[39m perceptron\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     55\u001b[0m     \u001b[39m#Testeo con el que entrene\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-------------- Entrenamiento con p=\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m----------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\ITBA\\4º Año\\Sistemas de Inteligencia Artificial (SIA)\\TPs-SIA\\TP3\\Ejercicio3\\src\\perceptron.py:108\u001b[0m, in \u001b[0;36mMultilayerPerceptron.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPERCENTAGE\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 108\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__train_percentage()\n\u001b[0;32m    109\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__train_k_fold()\n",
      "File \u001b[1;32me:\\ITBA\\4º Año\\Sistemas de Inteligencia Artificial (SIA)\\TPs-SIA\\TP3\\Ejercicio3\\src\\perceptron.py:149\u001b[0m, in \u001b[0;36mMultilayerPerceptron.__train_percentage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i]\u001b[39m.\u001b[39mcalc_error_d(np\u001b[39m.\u001b[39mdot(inherit_layer\u001b[39m.\u001b[39mweights,inherit_layer\u001b[39m.\u001b[39merror_d), activations[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m])\n\u001b[0;32m    148\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)):\n\u001b[1;32m--> 149\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i]\u001b[39m.\u001b[39;49mapply_delta(activations[i], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate, current_epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimization_method, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeta1, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeta2, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon)\n\u001b[0;32m    151\u001b[0m mse_errors\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_square_error(Os, expected))\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m (mse_errors[current_epoch] \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_error):\n",
      "File \u001b[1;32me:\\ITBA\\4º Año\\Sistemas de Inteligencia Artificial (SIA)\\TPs-SIA\\TP3\\Ejercicio3\\src\\layer.py:28\u001b[0m, in \u001b[0;36mLayer.apply_delta\u001b[1;34m(self, last_activation, learn_rate, t, optimization_method, alpha, beta1, beta2, epsilon)\u001b[0m\n\u001b[0;32m     25\u001b[0m act_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix(last_activation)\n\u001b[0;32m     26\u001b[0m err_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_d)\n\u001b[1;32m---> 28\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__update_weights(act_mat, err_mat, learn_rate, t, optimization_method, alpha, beta1, beta2, epsilon)\n",
      "File \u001b[1;32me:\\ITBA\\4º Año\\Sistemas de Inteligencia Artificial (SIA)\\TPs-SIA\\TP3\\Ejercicio3\\src\\layer.py:32\u001b[0m, in \u001b[0;36mLayer.__update_weights\u001b[1;34m(self, act_mat, err_mat, learn_rate, t, optimization_method, alpha, beta1, beta2, epsilon)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__update_weights\u001b[39m(\u001b[39mself\u001b[39m, act_mat, err_mat, learn_rate, t, optimization_method, alpha, beta1, beta2, epsilon):\n\u001b[0;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m optimization_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMOMENTUM\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learn_rate \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mdot(act_mat\u001b[39m.\u001b[39;49mT, err_mat) \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_delta\n\u001b[0;32m     33\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_delta \u001b[39m=\u001b[39m learn_rate \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(act_mat\u001b[39m.\u001b[39mT, err_mat) \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_delta\n\u001b[0;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learn_rate \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_d \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_bias\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import parse_nums\n",
    "from src.perceptron import MultilayerPerceptron\n",
    "\n",
    "#-------------------------------------------------\n",
    "# VARIANDO EL PORCENTAJE DE ENTRENAMIENTO\n",
    "#-------------------------------------------------\n",
    "\n",
    "PATH = \"./data/Ej3B-digitos.txt\"\n",
    "OUTPUT_ACTIVATION = \"TANH\"\n",
    "HIDDEN_ACTIVATION = \"TANH\"\n",
    "BETA = 1.0\n",
    "\n",
    "TRAINING_TYPE = \"PERCENTAGE\"\n",
    "LR = 0.001\n",
    "BIAS = 1\n",
    "EPOCHS = 50000\n",
    "MIN_ERROR = 0.01\n",
    "\n",
    "QTY_HIDDEN_LAYERS = 2\n",
    "QTY_NODES_IN_HIDDEN_LAYERS = [16, 10]\n",
    "\n",
    "OPTIMIZER_METHOD = [\"MOMENTUM\", \"ADAM\"]\n",
    "K_FOLD = 4\n",
    "ALPHA = 0.8\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "TRAIN_PERCENTAGES = [round(0.1*i,2) for i in range(4,11)]\n",
    "ITERATIONS = 50\n",
    "\n",
    "input_data, expected_data = parse_nums(PATH, 7, 2)\n",
    "\n",
    "arr_avg_train_mses = []\n",
    "arr_std_train_mses = []\n",
    "arr_avg_test_mses = []\n",
    "arr_std_test_mses = []\n",
    "\n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    avg_train_mses = []\n",
    "    std_train_mses = []\n",
    "    avg_test_mses = []\n",
    "    std_test_mses = []\n",
    "    for p in TRAIN_PERCENTAGES:\n",
    "        train = []\n",
    "        test = []\n",
    "        for iter in range(ITERATIONS):\n",
    "            perceptron = MultilayerPerceptron(input_data, expected_data, LR, BIAS,\n",
    "                                                EPOCHS, TRAINING_TYPE, p, K_FOLD, MIN_ERROR,\n",
    "                                                QTY_HIDDEN_LAYERS, QTY_NODES_IN_HIDDEN_LAYERS, \n",
    "                                                OUTPUT_ACTIVATION, HIDDEN_ACTIVATION, BETA,\n",
    "                                                opt_method, ALPHA, BETA1, BETA2, EPSILON,  [-1,1])\n",
    "            mse_errors, total_epochs, test_acurracy, test_mse = perceptron.train()\n",
    "            #Testeo con el que entrene\n",
    "            print(f\"-------------- Entrenamiento con p={p}----------------\")\n",
    "            if(p == 1):\n",
    "                train_acurracy, train_mse = perceptron.test(perceptron.input_data, perceptron.expected_data)\n",
    "            else:\n",
    "                train_acurracy, train_mse = perceptron.test(perceptron.train_input_data, perceptron.train_expected_data)\n",
    "            print(\"------------------------------\")\n",
    "            train.append(train_acurracy)\n",
    "            test.append(test_acurracy)\n",
    "            \n",
    "        train_aux = sum(train) / len(train)\n",
    "        avg_train_mses.append(train_aux)\n",
    "        error_train = np.std(train) / np.sqrt((len(train)))\n",
    "        std_train_mses.append(error_train)\n",
    "        \n",
    "        test_aux = sum(test) / len(test)\n",
    "        avg_test_mses.append(test_aux)\n",
    "        error_test = np.std(test) / np.sqrt((len(test)))\n",
    "        std_test_mses.append(error_test)\n",
    "                    \n",
    "    arr_avg_train_mses.append(avg_train_mses)\n",
    "    arr_std_train_mses.append(std_train_mses)\n",
    "    arr_avg_test_mses.append(avg_test_mses)\n",
    "    arr_std_test_mses.append(std_test_mses)\n",
    "    \n",
    "for i, opt_method in enumerate(OPTIMIZER_METHOD):\n",
    "    plt.errorbar(TRAIN_PERCENTAGES, arr_avg_train_mses[i], yerr=arr_std_train_mses[i], color=\"blue\", capsize=4, label=\"Train\")\n",
    "    plt.errorbar(TRAIN_PERCENTAGES, arr_avg_test_mses[i], yerr=arr_std_test_mses[i], color=\"red\", capsize=4, label=\"Test\")\n",
    "    plt.title(f'Perceptron Multicapa con optimizacion {opt_method} \\n output={OUTPUT_ACTIVATION}, hidden={HIDDEN_ACTIVATION}')\n",
    "    plt.xlabel(\"Porcentaje de entrenamiento\")\n",
    "    plt.ylabel(\"Acurracy\")\n",
    "    plt.legend(loc='best', bbox_to_anchor=(1.2, 1.0))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
